{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "torch.set_printoptions(profile=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        din, H1, H2, H3, H4, dout = 252, 100, 40, 100, 150, 2\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(din, H1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(H1, H2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(H2, dout),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(dout, H3),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(H3, H4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(H4, din),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def code(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    with open(path, 'r') as f:\n",
    "        data = f.readlines()[3:]\n",
    "        data = [float(data[i].strip()) for i in range(len(data))]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = []\n",
    "\n",
    "for i in range(10):\n",
    "    testdata.append(get_data(r'D:\\\\My Files\\\\核技术专题研讨\\\\Anode\\\\Anode\\\\c3--0000' + str(i) + '.csv'))\n",
    "for i in range(90):\n",
    "    testdata.append(get_data(r'D:\\\\My Files\\\\核技术专题研讨\\\\Anode\\\\Anode\\\\c3--000' + str(i+10) + '.csv'))\n",
    "for i in range(900):\n",
    "    testdata.append(get_data(r'D:\\\\My Files\\\\核技术专题研讨\\\\Anode\\\\Anode\\\\c3--00' + str(i+100) + '.csv'))\n",
    "for i in range(9000):\n",
    "    testdata.append(get_data(r'D:\\\\My Files\\\\核技术专题研讨\\\\Anode\\\\Anode\\\\c3--0' + str(i+1000) + '.csv'))\n",
    "for i in range(9243):\n",
    "    testdata.append(get_data(r'D:\\\\My Files\\\\核技术专题研讨\\\\Anode\\\\Anode\\\\c3--' + str(i+10000) + '.csv'))\n",
    "\n",
    "testdata = torch.tensor(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "learning_rate = 1e-3\n",
    "model = autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # ===================forward=====================\n",
    "    output = model(testdata)\n",
    "    loss = criterion(output, testdata)\n",
    "    # ===================backward====================\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.12f}'.format(epoch+1, num_epochs, loss.item()))"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch [1/100], loss:0.0159\n",
      "epoch [2/100], loss:0.0125\n",
      "epoch [3/100], loss:0.0102\n",
      "epoch [4/100], loss:0.0085\n",
      "epoch [5/100], loss:0.0074\n",
      "epoch [6/100], loss:0.0065\n",
      "epoch [7/100], loss:0.0059\n",
      "epoch [8/100], loss:0.0054\n",
      "epoch [9/100], loss:0.0050\n",
      "epoch [10/100], loss:0.0047\n",
      "epoch [11/100], loss:0.0044\n",
      "epoch [12/100], loss:0.0041\n",
      "epoch [13/100], loss:0.0039\n",
      "epoch [14/100], loss:0.0037\n",
      "epoch [15/100], loss:0.0036\n",
      "epoch [16/100], loss:0.0034\n",
      "epoch [17/100], loss:0.0033\n",
      "epoch [18/100], loss:0.0033\n",
      "epoch [19/100], loss:0.0032\n",
      "epoch [20/100], loss:0.0031\n",
      "epoch [21/100], loss:0.0030\n",
      "epoch [22/100], loss:0.0030\n",
      "epoch [23/100], loss:0.0029\n",
      "epoch [24/100], loss:0.0029\n",
      "epoch [25/100], loss:0.0029\n",
      "epoch [26/100], loss:0.0028\n",
      "epoch [27/100], loss:0.0028\n",
      "epoch [28/100], loss:0.0028\n",
      "epoch [29/100], loss:0.0027\n",
      "epoch [30/100], loss:0.0027\n",
      "epoch [31/100], loss:0.0027\n",
      "epoch [32/100], loss:0.0027\n",
      "epoch [33/100], loss:0.0026\n",
      "epoch [34/100], loss:0.0026\n",
      "epoch [35/100], loss:0.0026\n",
      "epoch [36/100], loss:0.0025\n",
      "epoch [37/100], loss:0.0025\n",
      "epoch [38/100], loss:0.0024\n",
      "epoch [39/100], loss:0.0024\n",
      "epoch [40/100], loss:0.0023\n",
      "epoch [41/100], loss:0.0022\n",
      "epoch [42/100], loss:0.0022\n",
      "epoch [43/100], loss:0.0021\n",
      "epoch [44/100], loss:0.0020\n",
      "epoch [45/100], loss:0.0018\n",
      "epoch [46/100], loss:0.0017\n",
      "epoch [47/100], loss:0.0016\n",
      "epoch [48/100], loss:0.0014\n",
      "epoch [49/100], loss:0.0013\n",
      "epoch [50/100], loss:0.0011\n",
      "epoch [51/100], loss:0.0010\n",
      "epoch [52/100], loss:0.0009\n",
      "epoch [53/100], loss:0.0007\n",
      "epoch [54/100], loss:0.0006\n",
      "epoch [55/100], loss:0.0005\n",
      "epoch [56/100], loss:0.0004\n",
      "epoch [57/100], loss:0.0004\n",
      "epoch [58/100], loss:0.0003\n",
      "epoch [59/100], loss:0.0003\n",
      "epoch [60/100], loss:0.0003\n",
      "epoch [61/100], loss:0.0003\n",
      "epoch [62/100], loss:0.0003\n",
      "epoch [63/100], loss:0.0002\n",
      "epoch [64/100], loss:0.0002\n",
      "epoch [65/100], loss:0.0002\n",
      "epoch [66/100], loss:0.0002\n",
      "epoch [67/100], loss:0.0002\n",
      "epoch [68/100], loss:0.0001\n",
      "epoch [69/100], loss:0.0001\n",
      "epoch [70/100], loss:0.0001\n",
      "epoch [71/100], loss:0.0001\n",
      "epoch [72/100], loss:0.0001\n",
      "epoch [73/100], loss:0.0001\n",
      "epoch [74/100], loss:0.0001\n",
      "epoch [75/100], loss:0.0001\n",
      "epoch [76/100], loss:0.0001\n",
      "epoch [77/100], loss:0.0001\n",
      "epoch [78/100], loss:0.0001\n",
      "epoch [79/100], loss:0.0001\n",
      "epoch [80/100], loss:0.0001\n",
      "epoch [81/100], loss:0.0001\n",
      "epoch [82/100], loss:0.0001\n",
      "epoch [83/100], loss:0.0001\n",
      "epoch [84/100], loss:0.0001\n",
      "epoch [85/100], loss:0.0001\n",
      "epoch [86/100], loss:0.0001\n",
      "epoch [87/100], loss:0.0001\n",
      "epoch [88/100], loss:0.0001\n",
      "epoch [89/100], loss:0.0001\n",
      "epoch [90/100], loss:0.0001\n",
      "epoch [91/100], loss:0.0001\n",
      "epoch [92/100], loss:0.0001\n",
      "epoch [93/100], loss:0.0001\n",
      "epoch [94/100], loss:0.0001\n",
      "epoch [95/100], loss:0.0001\n",
      "epoch [96/100], loss:0.0001\n",
      "epoch [97/100], loss:0.0001\n",
      "epoch [98/100], loss:0.0001\n",
      "epoch [99/100], loss:0.0001\n",
      "epoch [100/100], loss:0.0001\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "code() missing 1 required positional argument: 'x'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ffccc764d580>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# ===================log========================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch [{}/{}], loss:{:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: code() missing 1 required positional argument: 'x'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('auto encoder.txt', 'a') as f:\n",
    "    code = model.code(testdata)\n",
    "    for i in range(19243):\n",
    "        print(code[i][0].item(), code[i][1].item(), file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}